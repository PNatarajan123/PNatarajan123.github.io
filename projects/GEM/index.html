<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Self-Driving Polaris GEM | Praveen Natarajan </title> <meta name="author" content="Praveen Natarajan"> <meta name="description" content="Autonomous vehicle lane detection and waypoint navigation project"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://pnatarajan123.github.io/projects/GEM/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Praveen</span> Natarajan </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Self-Driving Polaris GEM</h1> <p class="post-description">Autonomous vehicle lane detection and waypoint navigation project</p> </header> <article> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <p>Below is a demonstration of autonomous vehicle systems algorithms applied in both real world and simulated scenarios.</p> <h2 id="nvidia-jetson-f1tenth-project">NVIDIA Jetson F1Tenth Project</h2> <p>The following is my project using an F1tenth car with an NVidia Jetson to navigate a track while recognizing traffic signs and reacting accordingly.</p> <div class="embed-responsive embed-responsive-16by9"> <iframe src="https://giphy.com/embed/daSJOod2ct26WRqpwN" class="embed-responsive-item" allowfullscreen=""></iframe> </div> <div class="caption"> F1Tenth Car Following Part of Track Using PID Controller </div> <div class="embed-responsive embed-responsive-16by9"> <iframe src="https://giphy.com/embed/xzFpB8xddj2NsKOb1Q" class="embed-responsive-item" allowfullscreen=""></iframe> </div> <div class="caption"> RViz Window of F1Tenth Car Following Track </div> <div class="embed-responsive embed-responsive-16by9"> <iframe src="https://giphy.com/embed/DNrANVVQ9sycg1l40q" class="embed-responsive-item" allowfullscreen=""></iframe> </div> <div class="caption"> F1Tenth Stop Sign Detection </div> <p>This project uses some of the below principles tested on a simulated GEM vehicle.</p> <h2 id="lane-detection">Lane Detection</h2> <p>The lane detection is shown through 2 different views. The rviz view on the top is sobel edge detection gradient threshold filtering combined with a color filter that filters in common white and yellow lane markings. The view on the bottom of the rviz screen is the birds eye view. This view is created by taking in a binary image and gradient threshold. Then, the binary image is put though a 3x3 transformation matrix using the <a href="https://docs.opencv.org/4.x/da/d54/group__imgproc__transform.html" rel="external nofollow noopener" target="_blank">cv2.getPerspectiveTransform()</a> function.</p> <div class="embed-responsive embed-responsive-16by9"> <iframe src="https://giphy.com/embed/JkTMoWDDpuufxiKPnx" class="embed-responsive-item" allowfullscreen=""></iframe> </div> <div class="caption"> Real World Lane Detection Example </div> <div class="embed-responsive embed-responsive-16by9"> <iframe src="https://giphy.com/embed/zh3bAGgGyS0UyoU0Ix" class="embed-responsive-item" allowfullscreen=""></iframe> </div> <div class="caption"> Another Real World Lane Detection Example </div> <div class="embed-responsive embed-responsive-16by9"> <iframe src="https://www.youtube.com/embed/NN2vsqcLwJA?si=2MWB7vqfK9gv0hnR" class="embed-responsive-item" allowfullscreen=""></iframe> </div> <div class="caption text-center"> Lane Detection Algorithm in Gazebo Simulator </div> <h2 id="waypoint-navigation">Waypoint Navigation</h2> <p>The waypoint navigation is created through longetudinal and lateral controllers. The longetudinal controller determines the speed of the vehicle depending on whether there is a curve in the road. If the GEM car detects a curve, the vehicle slows down to safely navigate around the turn, then speeds up once the turn is finished. For the lateral controller, I used the <a href="https://www.mathworks.com/help/nav/ug/pure-pursuit-controller.html" rel="external nofollow noopener" target="_blank">pure pursuit</a> algorithm to determine the turning angle of the car by processing lookahead points. The following algorithm was used in determining the turning angle of the GEM car:</p> \[\delta = \arctan\left( \frac{2L \cdot \sin(\alpha)}{ld} \right)\] <p>where:</p> <ul> <li>L is the length of the vehicle wheelbase,</li> <li>α is the angle between the vehicle’s heading and the look-ahead line,</li> <li>ld is the lookahead distance.</li> </ul> <div class="embed-responsive embed-responsive-16by9"> <iframe src="https://www.youtube.com/embed/GVSbcxOKyEM?si=776pPRJnbhWhioOG" class="embed-responsive-item" allowfullscreen=""></iframe> </div> <div class="caption text-center"> Waypoint Navigation in Gazebo Simulator </div> <h2 id="monte-carlo-localization">Monte Carlo Localization</h2> <p>In robotics, it is very difficult to determine where a robot is in a certain space. Monte Carlo Localization (MCL), also known as particle filter localization, offers a solution to this challenge by using a probabilistic approach to determine a robot’s position and orientation within a known map. As the robot moves, these particles are shifted based on the robot’s motion model, incorporating uncertainty to account for movement inaccuracies. Sensor data is then used to update the likelihood of each particle’s accuracy, with those matching more closely to the real-world data being deemed more probable. This step is followed by resampling, where particles with higher likelihoods are chosen to represent the robot’s new estimated state, allowing the algorithm to focus on the most probable locations. Below, the yellow turtle represents the estimated robot location, and the green turtle represents the actual robot location.</p> <div class="embed-responsive embed-responsive-16by9"> <iframe src="https://www.youtube.com/embed/SYovdYsZSRI?si=sMoiSOaJ4qCYmbK2" class="embed-responsive-item" allowfullscreen=""></iframe> </div> <div class="caption text-center"> Monte Carlo Localization with 8 Directional Measurement </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Praveen Natarajan. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>